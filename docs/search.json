[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Medium Articles",
    "section": "",
    "text": "Preface\nThis is a book that collects all of my Medium articles."
  },
  {
    "objectID": "01_scan.html#the-r-exams-package",
    "href": "01_scan.html#the-r-exams-package",
    "title": "1  Create, scan, and correct exams with R",
    "section": "1.1 The R exams package",
    "text": "1.1 The R exams package\nAs university instructors, we are creating exams and we use often multiple-choice questions to assess the knowledge of our students. I don’t know how many times I have manually corrected an exam which is why this blog gives a short introduction and shows why you should consider the R exams package for single or multiple choice exams (Grün and Zeileis 2009). The package provides features to automate the entire process, from generating the exam up to assigning grades.\nFirst, why should you consider R for exams? The exams package helps you to generate, scan, and assess the exam. It helps you to create a scan sheet that your students fill out in the exam. After the exam, you can use a regular copy machine to scan the sheets. The exams package scans those images, assess students’ answers, and provides documents with the results instantly. That is an awesome reason. Furthermore, it helps you to reduce mistakes because students’ answers are no longer corrected manually and it returns a HTML file for each participant that shows the scan sheet, the given and the correct answers, and how many points the person has earned.\nIn order to use exams, we need to setup a folder that contains all the question of the exam, we need the images of the exam to extract the information and we have to assess the students’ answers. Give it a try and learn how each step works before you setup your own exam, because the exams package comes with a nice tutorial and all necessary demo files to create and scan an exam. The next subsections give a quick summary of the demonstration from the website, but you can find a step-by-step guide on the R exams website website as well."
  },
  {
    "objectID": "01_scan.html#the-demo-from-the-r-exams-package",
    "href": "01_scan.html#the-demo-from-the-r-exams-package",
    "title": "1  Create, scan, and correct exams with R",
    "section": "1.2 The demo from the R exams package",
    "text": "1.2 The demo from the R exams package\nBefore we can start to create the exam, we need exercises or exam questions and the package provides a list of exercises files that we can download on the website. Make a new folder where all the files will be stored. Copy the exercises from the website and save them in a new folder named exercises. Next, create a new R script, install and load the library.\n\n#install.packages(\"exams\")\nlibrary(exams)\n\nAs a first step, we need to decide which questions should be included in the exam. Therefore, we create a list that stores questions names. In the last section, we will see how to create our own questions, but as first step it is fine if we use the questions provided by the exams package. As the next output shows, I created a list (exercises_exam) with several example questions:\n\n#setup a list of (example) exam questions\nexercises_exam &lt;- list(\n  \"tstat2.Rnw\",\n  \"ttest.Rnw\",\n  \"relfreq.Rnw\",\n  \"anova.Rnw\",\n  c(\"boxplots.Rnw\", \"scatterplot.Rnw\"),\n  \"cholesky.Rnw\"\n)\n\nSecond, I use this list to create the exam with the help of the exams2nops() function. The latter creates a PDF file based on the exercises_exam list and adds the scan sheet as first page. As the exams package outlines, you may want to set a seed to reproduce the results and we assign the exam as test_exam.\n\n#Create a PDF for the exam\nset.seed(403)\ntest_exam &lt;- exams2nops(exercises_exam, \n                  dir = \"nops_pdf\", \n                  name = \"demo\", date = \"2015-07-29\",\n                  points = c(1, 1, 1, 2, 2, 3),\n                  n = 2)\n\nThere are several options how to adjust the exam and you may check the documentation to adjust the minimal code for your own purposes. As the minimal code shows, we need to provide the directory (dir) where the pdf will be stored (here: nops_pdf), a name and the date of the exam; and I created two different versions of the exam (with randomized order of the questions), but you can create more versions if you want to. In addition to the pdf files, the exams2nops() function saves a .rds file in the directory which contains all of the meta data about the exam (e.g. solutions). We will see where this information is coming from in the last section.\nThe package provides everything that is needed for a test run and includes also test exam images. The next code snippet saves two example scan files as scan_image. We can use the two files to see how we can evaluate images and scan an exam.\n\n#Use example images to check out how it works\nscan_image &lt;- dir(system.file(\"nops\", package = \"exams\"), \n           pattern = \"nops_scan\",\n           full.names = TRUE)\n\nAll of the scan images must be stored in one directory. Create a new directory with dir.create(\"nops_scan\") where the scan files will be saved and the second line of code copies the demo files scan_image into the nops_scan folder with file.copy().\n\n#Create a folder and copy images\ndir.create(\"nops_scan\")\nfile.copy(scan_image, to = \"nops_scan\")\n\nAfter you run this code chunk, two fake scan images appear in your folder, one from Ambi Dexter and another one from Jane Doe, as the next figure illustrates.\n\nAfter we have prepared all the essential steps, we use the nops_scan() function to scan the images. It trims and rotates the files and extracts the information from the PNG.\n\n#Scan images\nnops_scan(dir = \"nops_scan\")\n\nHave a look in your directory. The nops_scan() function saves the result as a archive, which includes the png files as well as a text file with the extracted information.\nBefore we can finally evaluate the results, we need a list with the information of our students to match them with the results of the exam. The minimal example gives you a code snippet to create a csv file that contains the information about the two fake students from the demo.\n\n#Who participates the exam? Load data or use example data \nwrite.table(data.frame(\n  registration = c(\"1501090\", \"9901071\"),\n  name = c(\"Jane Doe\", \"Ambi Dexter\"),\n  id = c(\"jane_doe\", \"ambi_dexter\")), \n  file = \"Exam-2015-07-29.csv\", sep = \";\", quote = FALSE, row.names = FALSE)\n\nFinally, we can use the nops_eval() function to evaluate the scanned images. The register points to the students’ matching list, solutions points to the meta data of the exam, scans provides the directory and name of the scan results, eval determines how the results are evaluated (e.g. do we give partial points), and interactive gives information whether errors should be handled interactively or not. Check out the documentation of nops_eval() for more information.\n\n#Extract/Eval information from images\nexam_results &lt;- nops_eval(\n  register = \"Exam-2015-07-29.csv\",\n  solutions = \"nops_pdf/demo.rds\",\n  scans = Sys.glob(\"nops_scan/nops_scan_*.zip\"),\n  eval = exams_eval(partial = FALSE, negative = FALSE),\n  interactive = TRUE\n)\n\nAnyway, the nops_eval() returns a data frame that contains the answers, solutions, and given points for each student!\n\n#Inspect results\nexam_results\n\n\nCheckout your folder. The nops_eval() function has already exported the exam file and it created an archive that contains a short summary document of the exam results for each student. As the next figure shows, it displays the meta information of your students, an assessment of each question, and the image of the scan sheet used to extract the information. Thus, you are really prepared if your students show up to review the exam.\n\nThus, the exams package reduces a lot of pain when it comes to correct exams and I really hope, that I have convinced you that you can handle the discussed steps, even if you have limited experience using R. To boost the popularity of the package, and to convince you that you should stick to R for the next steps as well, the next section shows you how can use R to prepare the data and automate the process to communicate the exam results. Sure, you can use any software to finalize the data, but R gives you some nice features to automate this process and you can even use R to make a summary document for your students without much effort. Unfortunately, this implies that I assume in the next section that you have basic R knowledge."
  },
  {
    "objectID": "01_scan.html#r-is-your-exam-friend",
    "href": "01_scan.html#r-is-your-exam-friend",
    "title": "1  Create, scan, and correct exams with R",
    "section": "1.3 R is your exam friend",
    "text": "1.3 R is your exam friend\nHow do we communicate the results of the exam and how can we automate this process? The data is saved as nops_eval.csv and we can use R to wrangle the exam data, prepare a final list with the results (a list to enter grades in the educational system), and to communicate the exam results.\nObviously, the exam data is already loaded, but we have to import the data if we want to provide a short summary for the participants or if we want to rerun the data management steps. Thus, use the readr package to import the data and the tidyverse approach for data wrangling (Wickham 2022). If you are not familiar with loading data in R, import the data with the import data function in RStudio. It gives you a preview of the data, shows you the corresponding packages and the code to import the data. As the following code snippet shows, you can read a delimited file (including csv & tsv) with the read_delim() function and we have to tweak the delimiters, because our file contains semicolons instead of commas to separate values.\n\n#Load data\nlibrary(readr)\nexam_df &lt;- read_delim(\"nops_eval.csv\", \n                        \";\", escape_double = FALSE, trim_ws = TRUE)\n\nNext, I exclude all variables which are not longer necessary for the report after importing that data. The dplyr package gives a lot handy functions to work with data and the package is included in the tidyverse package (Wickham et al. 2023). We can use the select() function to make a narrow data frame with an ID variable (register number) and the points variable from the exam data only. I generated some fake data to illustrate this process, but the code shows you furthermore how you can save a new data frame with the selected variables:\n\n#Fake example data\nlibrary(tidyverse)\nexam_df &lt;- tribble(\n  ~ID, ~points,\n   1, 57,\n   2, 60,\n   3, 84,\n   4, 45,\n   5, 82\n)\n\nexam_df &lt;- exam_df  %&gt;% \n  select(ID, points)\nexam_df\n\n# A tibble: 5 × 2\n     ID points\n  &lt;dbl&gt;  &lt;dbl&gt;\n1     1     57\n2     2     60\n3     3     84\n4     4     45\n5     5     82\n\n\nAgain, the exam package makes our life very easy since there is not much to do which is why I try to encourage people to use R even if you have little experience using it. As the next code chunk illustrates, we have to generate a new variable that stores the grade depending on the points people have achieved. Use mutate() to extend the data frame and the case_when() function assigns grades in accordance to the points of the exam. I decided that grade level goes from 100 to 50 points with a range of 5 points for each grade level, but that is not the important point here. The case_when() function checks whether the condition (e.g. points &gt;= 95 ~ 1.0) is fulfilled and assigns the corresponding grade if that’s the case. Let’s see how it works:\n\n#Give grades according to points\nexam_df &lt;- exam_df %&gt;% \n  mutate(\n    grade = (\n      case_when(\n        points &gt;= 95 ~ 1.0,\n        points &gt;= 90 ~ 1.3,\n        points &gt;= 85 ~ 1.7,\n        points &gt;= 80 ~ 2.0,\n        points &gt;= 75 ~ 2.3,\n        points &gt;= 70 ~ 2.7,\n        points &gt;= 65 ~ 3.0,\n        points &gt;= 60 ~ 3.3,\n        points &gt;= 55 ~ 3.7,\n        points &gt;= 50 ~ 4.0,\n        points &lt;= 49 ~ 5.0\n      )\n    )\n  )\n\nexam_df\n\n# A tibble: 5 × 3\n     ID points grade\n  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1     1     57   3.7\n2     2     60   3.3\n3     3     84   2  \n4     4     45   5  \n5     5     82   2  \n\n\nAs the output shows, Person 1 has 57 points and gets the grade 3.7 (German grading system); person 4 gets the grade 5 because he/she has achieved less than 50, and so on. Please check each grade level to make sure that there are no mistakes, no typos, or any other problems.\nThe next steps depend on how you have to enter the grades in your higher educational system. For instance, I need a sorted list and the grades multiplied by 100 at my university. Nothing easier than that, use mutate() again to extend our data frame with an additional grade and use arrange() to sort the data.\n\n#Arrange and check if data preparation steps really worked\nexam_df %&gt;% \n  mutate(grade_system = grade * 100) %&gt;%\n  arrange(ID)\n\n# A tibble: 5 × 4\n     ID points grade grade_system\n  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;\n1     1     57   3.7          370\n2     2     60   3.3          330\n3     3     84   2            200\n4     4     45   5            500\n5     5     82   2            200\n\n\nFinally, I need to match the exam list with a list of students who have actually registered for the exam, but some did not show up in the exam. This step also depends on what your institution wants from you, which makes it hard for me to give you any useful advice. You may want to check out how to merge data (in my case I used a left_join()); after I merged the data, I save the final results with the readr package, for example, as a csv file.\n\n#In case you need to save your results\nwrite_csv(final_results, \"final_results.csv\")\n\nThus, you can create, scan and correct exams even if you have only limited knowledge about R, but I know from my own experience that the start can be tricky and we all need sometimes an incentive.\nI guess reducing mistakes when correct exams is already an huge incentive, but you can also use R to generate a small report for your students. You may want to check out rmarkdown which let you easily create different files (pdf, html, word) and I have a standard document for my students that contains a table as well as a histogram that depicts the exam grades (Allaire et al. 2022). The next console shows the code to generate such a histogram with the help of the ggplot2 package (Wickham et al. 2022).\n\n#Inspect the results visually\nmean_grade &lt;- exam_df %&gt;% \n  pull(grade) %&gt;% \n  mean() %&gt;% \n  round(2)\n\n#Plot it\nggplot(exam_df, aes(x=grade)) +\n  geom_histogram(colour=\"black\", fill=\"white\", bins = 11)+\n  geom_vline(xintercept=mean_grade, size=1.5, color=\"red\")+\n  geom_text(aes(x=mean_grade+0.5, label=paste0(\"Mean\\n\",mean_grade), y=8))+\n  theme_minimal(base_size = 14)\n\n\n\n\nThe ggplot2 package, rmarkdown, r-exam, maybe you feel a lit bit overwhelmed depending on your background. I just wanted to outline the advantages if we create all steps in the same environment, and R gives you the possibilities to do all essential steps when it comes to exams. Moreover, it is very easy to learn rmarkdown or ggplot2 in case you have never heard of it before. I hope that the code examples give you a start how to apply it on your own. You could even have my own RMarkdown template, but RStudio comes with several rmarkdown templates and if you copy the code from above, you have essentially the same as I use.\nFrom my opinion there is only one thing left for me to do. You have to create your own exercises before you can think of using R for your exams."
  },
  {
    "objectID": "01_scan.html#create-your-own-exercises",
    "href": "01_scan.html#create-your-own-exercises",
    "title": "1  Create, scan, and correct exams with R",
    "section": "1.4 Create your own exercises",
    "text": "1.4 Create your own exercises\nThe next output shows you an example of an exercise. The exercises need to be available as a Markdown or a RMarkdown file. Obviously, another good reason why you want to learn more about RMarkdown. Anyway, even if you are not familiar with both, creating new exercises is easy and the structure of the exercises is not complicated.\nQuestion\n========\nWhat is the question?\n\nAnswerlist\n----------\n\n* A\n* B\n* C\n* D\n\nSolution\n========\nA and C\n\nAnswerlist\n----------\n* True\n* False\n* True\n* False\n\nMeta-information\n================\nexname: question1\nextype: mchoice\nexsolution: 1010\nexshuffle: TRUE\nI don’t think there is much to say how to provide a question, answerlist or the solutions. So, let’s have a look at the meta-information at the end of the exercise. In this section you have to outline whether you use a single (schoice) or multiple choice (mchoice); exsolution points to the binary string code for the solutions, here A and C are right which leads to 1010. Ultimately, you can decide whether the answers of the questions is shuffled or not.\nThe R exams package has much more to offer than I could possibly show you. I just tried to give a quick summary how R can be used for exams. Visit the R exams website for tutorials, the dynamic exercises, or e-learning tests. But most of all I hope that I could convince some people that learning how to create, scan, and correct exams with R is no magic at all.\n\n\n\n\nAllaire, JJ, Yihui Xie, Jonathan McPherson, Javier Luraschi, Kevin Ushey, Aron Atkins, Hadley Wickham, Joe Cheng, Winston Chang, and Richard Iannone. 2022. Rmarkdown: Dynamic Documents for r. https://CRAN.R-project.org/package=rmarkdown.\n\n\nGrün, Bettina, and Achim Zeileis. 2009. “Automatic Generation of Exams in r” 29. https://doi.org/10.18637/jss.v029.i10.\n\n\nWickham, Hadley. 2022. Tidyverse: Easily Install and Load the Tidyverse. https://CRAN.R-project.org/package=tidyverse.\n\n\nWickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen, Kohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, and Dewey Dunnington. 2022. Ggplot2: Create Elegant Data Visualisations Using the Grammar of Graphics. https://CRAN.R-project.org/package=ggplot2.\n\n\nWickham, Hadley, Romain François, Lionel Henry, Kirill Müller, and Davis Vaughan. 2023. “Dplyr: A Grammar of Data Manipulation.” https://CRAN.R-project.org/package=dplyr."
  },
  {
    "objectID": "02_master_sql.html#run-sql-queries-from-r",
    "href": "02_master_sql.html#run-sql-queries-from-r",
    "title": "2  Master SQL with R",
    "section": "2.1 Run SQL queries from R",
    "text": "2.1 Run SQL queries from R\nMany books and courses introduces SQL and they outline in depth what SQL (structured query language) is. A lot of them go beyond this step, they start to introduce different databases backends (e.g., MySQL, MariaDB), CLI commands to interact with databases, and they show how to setup software or at least introduce a web interface to interact with a database.\nCertainly, these topics increase our understanding, but this seems a lot of effort considering your first goal is to familiarize yourself with SQL. We need to practice SQL and the described steps make the learning curve pretty steep. Fortunately, for R users there is no need to install software or create a database to run your first queries. Consider the next console with a simple SQL code snippet. It illustrates that we often start with a select step since we need to retrieve data from the database. We select one, several, or all columns (*) from the table. Later I’ll show you that we can use R and translate R code into SQL, so keep this simple SQL snippet in mind:\n\n--Example SQL Code\nSELECT var FROM data;\n\nIn further steps we may learn how to filter the data and set a condition (in SQL we apply a WHERE clause); we learn how to count (COUNT) cases, or do some basic calculations such as calculating the mean (AVG). You can write and run all of these queries without leaving R. Let’s keep it simple. Suppose we want to learn how to select a variable and calculate the mean:\n\nSELECT AVG(var) FROM data;\n\nThe sqldf package let us apply SQL code snippets to a data frame (Grothendieck 2017). You can build your SQL skills and follow a course without a large setup, without our own database, or any cloud solution in the beginning. Install the package (via install.packages) and write your first queries from R. How about the mean consumption of cars with the implemented mtcars data:\n\n#Run SQL code from R\nlibrary(sqldf)\nsqldf('SELECT AVG(mpg) FROM mtcars;')\n\n#&gt;   AVG(mpg)\n#&gt; 1 20.09062\n\n\nThe sqldf package makes it very convenient to run a few SQL snippets and the package outlines how we interact with different SQL databases in its documentation: ” sqldf() transparently sets up a database, imports the data frames into that database, performs the SQL select or other statement and returns the result using a heuristic to determine which class to assign to each column of the returned data frame” (Grothendieck 2017).\nAgain, there is no need to establish a real database in the beginning, we can make use of the local memory to simulate a database, save a table (data frame) and run SQL commands directly as a code chunk from the R script exactly as the sqldf package does. The RSQLite package helps us with this task, it creates the SQLite database on your local machine (Müller et al. 2022). With this approach, it is almost like if we work with a real database, but it is still very convenient for beginners. To do so, we need to establish a connection to the database and this code chunk will also work as a template in the near future when you switch from the local to the real database.\nHow do we connect R with a database? Use the DBI package to connect to many different databases (R Special Interest Group on Databases (R-SIG-DB), Wickham, and Müller 2022). In a nutshell, we need to establish a connection (con) with the dbConnect() function. This implies that we need to pick a driver (drv) to connect to a specific database (e.g., RMariaDB::MariaDB() for MariaDB; or RSQLServer::SQLServer for Postgres, etc.); furthermore, we need to provide the properties needed to get access to the database (e.g., host, username, etc.).\nThe DBI package gives us the code to illustrate this step with a guest account for a MariaDB database.\n\n#Establish a connection\nlibrary(DBI)\n\ncon &lt;- dbConnect(\n  drv = RMariaDB::MariaDB(),\n  dbname = \"sakila\",\n  host = \"relational.fit.cvut.cz\",\n  port = 3306,\n  username = \"guest\",\n  password = \"relational\"\n)\n\nAfter we made the connection, check if the approach worked. The dbListTables() functions lists all available tables of the connected database.\n\n#List all available tables/data\ndbListTables(con)\n#  [1] \"actor\"         \"address\"       \"category\"     \n#  [4] \"city\"          \"country\"       \"customer\"     \n#  [7] \"film\"          \"film_actor\"    \"film_category\"\n# [10] \"film_text\"     \"inventory\"     \"language\"     \n# [13] \"payment\"       \"rental\"        \"staff\"        \n# [16] \"store\"     \n\nKeep in mind that we do not want to share sensitive information such as the user name or password in the code. Use the askForPassword() function from the rstudioapi package (Ushey et al. 2023). It forces us to insert the password each time we connect. Or use the keyring package to save the key savely in your environment and not in the code (Csárdi 2022). Irrespective of the used approach, we connect to the database, retrieve and wrangle data, and finally disconnect before we can go on.\n\n#Disconnect after have finished the job\ndbDisconnect(con)\n\nI claimed that we can run this step without having access to a database. That’s where the RSQLite package comes into play. The SQLite() function creates the SQLite database on your local machine if you use :memory: as database name (dbname).\n\n# Create in-memory RSQLite database\ncon &lt;- dbConnect(drv = RSQLite::SQLite(), \n                 dbname = \":memory:\")\n\nThis creates an empty database which is why we need to insert a table into the local database first.\n\n#Write a table into the data base\ndbWriteTable(conn = con, \n             name = \"mtcars\", \n             value = mtcars)\n\nThe dbSendQuery() function let you sent SQL queries to the connected database, dbFetch shows the result, and we can clear the result after we have finished.\n\n#Send queries to the local database\nresult_DB &lt;- dbSendQuery(con, \"SELECT AVG(mpg) FROM mtcars;\")\ndbFetch(result_DB)\n\n#&gt;   AVG(mpg)\n#&gt; 1 20.09062\n\ndbClearResult(result_DB)\n\nSuch R packages increases our learning curve substantially, since we can create a database and write SQL code without any other equipment than our local machine. In addition, the dbplyr package will help us to combine our R skills with SQL, it even translate R into SQL."
  },
  {
    "objectID": "02_master_sql.html#the-dbplyr-package",
    "href": "02_master_sql.html#the-dbplyr-package",
    "title": "2  Master SQL with R",
    "section": "2.2 The dbplyr package",
    "text": "2.2 The dbplyr package\nAs outlined on the package website: “dbplyr is the database backend for dplyr (Wickham, Girlich, and Ruiz 2022). It allows you to use remote database tables as if they are in-memory data frames by automatically converting dplyr code into SQL.” Thus, we can apply common dplyr verbs to SQL databases. First, we need to create a table from a database with the tbl() function.\n\n#Create a table from the database\nlibrary(dplyr)\nlibrary(dbplyr)\n\nmtcars_db &lt;- tbl(con, \"mtcars\")\n\nLet us go back to example SQL code snippet. Suppose we didn’t know how to select and calculate the mean in SQL. There are several ways to calculate it with R, but the tidyverse approach is not difficult (Wickham 2022); and it let us apply our dplyr knowledge thanks to the dbplyr package. The summarise() function collapses the data and we get the mean() by including it in the latter step, however, only if we run the code locally.\n\n#Get mean with dplyr (locally)\nmtcars |&gt; \n  summarise(mean_mpg = mean(mpg))\n\n#&gt;   mean_mpg\n#&gt; 1 20.09062\n\n\nIn order to apply this step in our database, we must assign the data manipulation steps (here as summary) and we must execute the query to retrieve results via the collect() function.\n\n#Get mean with dbplyr\nsummary &lt;- mtcars_db |&gt; \n  summarise(mean_mpg = mean(mpg))\n\n#Collect (execute and retrieve) the result from the db\nsummary |&gt;  collect()\n\n#&gt; # A tibble: 1 × 1\n#&gt;   mean_mpg\n#&gt;      &lt;dbl&gt;\n#&gt; 1     20.1\n\n\nWhat is happening under the hood? How can we apply R code to SQL? The package has a show_query() function which shows the underlying SQL code that we sent to the database.\n\n#Inspect SQL query\nsummary |&gt;  show_query()\n\n#&gt; &lt;SQL&gt;\n#&gt; SELECT AVG(`mpg`) AS `mean_mpg`\n#&gt; FROM `mtcars`\n\n\nThe packages has more to offer than I possibly can outline. For example, translate_sql() let you translate SQL code. This may help with your learning curve and it also highlights that there are different SQL dialects depending on the database you work with. Suppose to need to clean data. How can we manipulate strings to lower case in SQL? In R we may use the tolower() function:\n\n#tolower returns strings in lower case\ntolower(\"HeLLo WoRld\")\n\n#&gt; [1] \"hello world\"\n\n\nThe translate_sql() function translate it to SQL and we can see differences between SQL dialects such as SQLite and Access (LOWER and LCASE) if we simulate different engines (e.g., simulate_sqlite).\n\n#Translate with different SQL engines\ntranslate_sql(tolower(\"HeLLo WoRld\"), con = simulate_sqlite())\n\n#&gt; &lt;SQL&gt; LOWER('HeLLo WoRld')\n\ntranslate_sql(tolower(\"HeLLo WoRld\"), con = simulate_access())\n\n#&gt; &lt;SQL&gt; LCASE('HeLLo WoRld')\n\n\nGo the website to learn more about dbplyr; however, I have one last one last advice for the road."
  },
  {
    "objectID": "02_master_sql.html#document-sql-with-rmarkdown-and-quarto",
    "href": "02_master_sql.html#document-sql-with-rmarkdown-and-quarto",
    "title": "2  Master SQL with R",
    "section": "2.3 Document SQL with Rmarkdown and Quarto",
    "text": "2.3 Document SQL with Rmarkdown and Quarto\nIf I do not work with a language on a regular base, I forget how it works instantly. Thus, code documentation is an important issue. In R we create documents with rmarkdown, but we can also include different languages - including SQL - in an rmarkdown or a Quarto document. Go the rmarkdown website if have never created documents with R, because we can create a document with text, (SQL) code, and the output to summarize what you have achieved so far. Moreover, you can be sure that the code contains no mistake since the code runs when the document is created.\nSay we want to document the SQL code from the beginning:\n\n--Example SQL Code\nSELECT AVG(mpg) FROM mtcars;\n\n\n1 records\n\n\nAVG(mpg)\n\n\n\n\n20.09062\n\n\n\n\n\nFirst, you need to create the connection to the database. Create a new rmarkdown document and insert the code to create a connection inside the setup-chunk. Second, insert a code chunk into the document, but this time a SQL code chunk and point to the database via the connection chunk-option. This makes it possible to run the SQL code and it returns the output as result. The next code shows how such code chunk looks like in an R Markdown document:\n\n\n```{sql connection=con}\n--Example SQL Code\nSELECT AVG(mpg) FROM mtcars;\n```\n\n\nI hope you find the discussed tips helpful, at least, I missed them when I started to learn SQL.\n\n\n\n\nCsárdi, Gábor. 2022. “Keyring: Access the System Credential Store from r.” https://CRAN.R-project.org/package=keyring.\n\n\nGrothendieck, G. 2017. “Sqldf: Manipulate r Data Frames Using SQL.” https://CRAN.R-project.org/package=sqldf.\n\n\nMüller, Kirill, Hadley Wickham, David A. James, and Seth Falcon. 2022. RSQLite: SQLite Interface for r. https://CRAN.R-project.org/package=RSQLite.\n\n\nR Special Interest Group on Databases (R-SIG-DB), Hadley Wickham, and Kirill Müller. 2022. DBI: R Database Interface. https://CRAN.R-project.org/package=DBI.\n\n\nUshey, Kevin, JJ Allaire, Hadley Wickham, and Gary Ritchie. 2023. “Rstudioapi: Safely Access the RStudio API.” https://CRAN.R-project.org/package=rstudioapi.\n\n\nWickham, Hadley. 2022. Tidyverse: Easily Install and Load the Tidyverse. https://CRAN.R-project.org/package=tidyverse.\n\n\nWickham, Hadley, Maximilian Girlich, and Edgar Ruiz. 2022. Dbplyr: A Dplyr Back End for Databases. https://CRAN.R-project.org/package=dbplyr."
  },
  {
    "objectID": "03_ggplot2_ext.html#alluvial",
    "href": "03_ggplot2_ext.html#alluvial",
    "title": "3  Ten additional geoms for ggplot2",
    "section": "3.1 01 Alluvial",
    "text": "3.1 01 Alluvial\nAlluvial charts show how proportions develop over time and are therfore ideal to highlight the interrelatedness of variables or the flow of a process. As the example plot shows, I used official data from German School Departments to depict the change of school types (downward and upward mobility) within a given year. As the plot shows, most pupils to a lower school type and in consequence downward mobility is larger in Germany.\n\n\n\n\n\nThe ggalluvial package implements an alluvial plot as an ggplot2 (see Brunson and Read 2020). For example, you may use the titanic data to examine who survived the sinking of the Titanic. The alluvial chart helps us depict how socio-demographic variables such as sex, age, or class are related in terms of survival. The geom_stratum() function draws boxes that display the frequency of each group level and the geom_alluvium() shows the flow between groups.\n\n#Minimal code example #####\nlibrary(ggplot2)\nlibrary(ggalluvial)\n#A wide data format\ntitanic_wide_format &lt;- data.frame(Titanic)\n\nggplot(data = titanic_wide_format,\n       aes(axis1 = Class, axis2 = Sex, axis3 = Age, y = Freq)) +\n  geom_alluvium(aes(fill = Survived)) +\n  geom_stratum()"
  },
  {
    "objectID": "03_ggplot2_ext.html#beeswarm-plots",
    "href": "03_ggplot2_ext.html#beeswarm-plots",
    "title": "3  Ten additional geoms for ggplot2",
    "section": "3.2 02 Beeswarm plots",
    "text": "3.2 02 Beeswarm plots\nScatter plots are awesome to examine a relationship, but sometimes there are too many observations to see what is going on and single points are no longer visible. A beeswarm plot decreases over-plotting by adding vertical noise. It is a categorical scatter plot that shows the distribution of a numerical variable for each category (Clarke and Sherrill-Mix 2017). For example, the following plot depicts body mass for each species and sex of the palmerpenguins data (Horst, Hill, and Gorman 2020).\n\n\n\n\n\nThe ggbeeswarm package provides several methods to reduce over-plotting (e.g., pseudorandom, smiley). The geom_quasirandom() function adds quasi-random noise to each observation as a default method.\n\n#Minimal code example #####\nlibrary(ggbeeswarm)\n\nggplot(penguins, aes(species, body_mass_g, \n                     color = sex)) + \n    geom_quasirandom()"
  },
  {
    "objectID": "03_ggplot2_ext.html#choropleth-maps",
    "href": "03_ggplot2_ext.html#choropleth-maps",
    "title": "3  Ten additional geoms for ggplot2",
    "section": "3.3 03 Choropleth maps",
    "text": "3.3 03 Choropleth maps\nCreate a choropleth map with ggplot2. The latter displays a geographical area (or region) and, for example, fills the shape of the area. The next plot displays the number of arrests in the US. It takes time and effort to create a choropleth map, but the result is worth the trouble.\n\n\n\n\n\nIn addition, the ggmap package helps to create maps (Kahle, Wickham, and Jackson 2019; Kahle and Wickham 2013), because we need to draw the shape of each area (e.g., country shape) first. The shape must be displayed by its longitude and latitude before we can fill the area or display numbers that describe the area. The minimal code does not need any additional package and shows an example from the ggplot2 cheat sheet. If the corresponding geographical areas can be matched with the data, geom_map() draws the map and fills each area with the observed value.\n\n#Minimal code example #####\n#Source: This example comes from the ggplot2 cheat sheet!\nmap &lt;- map_data(\"state\")\ndata &lt;- data.frame(murder = USArrests$Murder,\n                   state = tolower(rownames(USArrests)))\n\nggplot(data, aes(fill = murder))+\n  geom_map(aes(map_id = state), map = map)+\n  expand_limits(x = map$long, y = map$lat)"
  },
  {
    "objectID": "03_ggplot2_ext.html#dots-dots-dots",
    "href": "03_ggplot2_ext.html#dots-dots-dots",
    "title": "3  Ten additional geoms for ggplot2",
    "section": "3.4 04 Dots dots dots",
    "text": "3.4 04 Dots dots dots\nBla bla\n\n\n\n\n\nCreating a word cloud is not rocket since, but working with text is a complicated topic in the beginning. Fortunately, there is no need to learn text mining first, the ggwordcloud package includes data to make word clouds. Consider reading Text Mining with R by Silge and Robinson (2017) to learn more about text mining.\n\nlibrary(dotwhisker)\nlibrary(palmerpenguins)\n\nm1 &lt;- lm(flipper_length_mm ~ bill_length_mm,\n           data = penguins)\nm2 &lt;- lm(flipper_length_mm ~ bill_length_mm + sex,\n           data = penguins)\n\ndwplot(list(m1, m2),\n       vline = geom_vline(xintercept = 0))"
  },
  {
    "objectID": "03_ggplot2_ext.html#dumbbell-and-lollipop-charts",
    "href": "03_ggplot2_ext.html#dumbbell-and-lollipop-charts",
    "title": "3  Ten additional geoms for ggplot2",
    "section": "3.5 044 Dumbbell and lollipop charts",
    "text": "3.5 044 Dumbbell and lollipop charts\nThe ggplot2 package lets you build a graph from scratch, but creating a visualization is hard work. The ggcharts package is for the lazy cats and gives access to a lot of common charts (Neitmann 2020). The package has implemented those graphs with its own functions, and we don’t have to create each step on our own. Furthermore, the package returns ggplot2 objects, which implies that you can apply your ggplot2 knowledge as well.\nFor example, create a dumbbell or a lollipop chart. I used the former to examine how life expectancy increased between 1952 and 2007 based on the gapminder data. The example shows the top 10 European countries with the highest increase in life expectancy.\n\n\n\n\n\n\n#Minimal code example #####\nlibrary(ggcharts)\ndata(\"popeurope\")\n\ndumbbell_chart(popeurope, \n               x = country,\n               y1 = pop1952, y2 = pop2007,\n               top_n = 10)"
  },
  {
    "objectID": "03_ggplot2_ext.html#hexbin-map",
    "href": "03_ggplot2_ext.html#hexbin-map",
    "title": "3  Ten additional geoms for ggplot2",
    "section": "3.6 05 Hexbin map",
    "text": "3.6 05 Hexbin map\nBuild a hexbin map with ggplot2. It displays hexagons as shapes. Actually, this graph is as an Easter egg since we do not need any additional package to make this plot. There are a lot of great extensions for ggplot2, but you can create many graphs with ggplot2 alone and we did not explore all geoms. For example, the geom_polygon() function creates the hexbin map and here it shows US unemployment rates.\n\n\n\n\n\nThe graph is inspired by r-graph-gallery.com website. It shows a great variety of (ggplot2) visualization, provides a lot of resources to create plots, and has articles that discuss the limitations of graphs as well. Have you ever seen a radar, a stream, or a sunburst chart? Visit the website and learn how to make them.\n\n#Minimal code example #####\n#There are many graphs (and code) to explore on:\n#www.r-graph-gallery.com"
  },
  {
    "objectID": "03_ggplot2_ext.html#mosaic-plots",
    "href": "03_ggplot2_ext.html#mosaic-plots",
    "title": "3  Ten additional geoms for ggplot2",
    "section": "3.7 06 Mosaic plots",
    "text": "3.7 06 Mosaic plots\nMosaic (or spine) plots are very powerful when visualizing descriptive results, and we created one with base R in Chapter 3. However, mosaic plots are also implemented in ggplot2. The ggmosaic() package provides the corresponding geom (Jeppson, Hofmann, and Cook 2021). The illustration uses the titanic data and depicts the effect of passenger’s sex on survival. Obviously, more women than men survived the accident.\n\n\n\n\n\nAs the minimal code illustrates, the geom_mosaic comes with a product() function to estimate frequencies for each category and fills each box accordingly.\n\n#Minimal code example #####\nlibrary(ggmosaic)\n\nggplot(data = titanic) +\n  geom_mosaic(aes(x = product(Sex), \n                  fill = Survived))"
  },
  {
    "objectID": "03_ggplot2_ext.html#ridge-plots",
    "href": "03_ggplot2_ext.html#ridge-plots",
    "title": "3  Ten additional geoms for ggplot2",
    "section": "3.8 07 Ridge plots",
    "text": "3.8 07 Ridge plots\nCompare the distribution of a numeric variable with a ridge plot (Wilke 2021). In the example, I used the gapminder data to inspect how life expectancy differs between continents in 2007. As the plots shows, Europe has the highest, while Africa had the lowest life expectancy. The distribution is much wider in Africa compared to other continents.\n\n\n\n\n\nThe ggridges package comes with data and a lot of illustrative examples provided by Claus Wilke, the author of the package. As the code from the vignette illustrates, explore how the weather (temperature) develops within a year.\n\n#Minimal code example #####\nlibrary(ggridges)\n\n#Minimal code by Claus Wilke:\nggplot(lincoln_weather, aes(x = `Mean Temperature [F]`, y = Month, \n                            fill = stat(x))) +\n  geom_density_ridges_gradient(scale = 3, \n                               rel_min_height = 0.01) +\n  scale_fill_viridis_c(name = \"Temp. [F]\", \n                       option = \"C\")"
  },
  {
    "objectID": "03_ggplot2_ext.html#treemaps",
    "href": "03_ggplot2_ext.html#treemaps",
    "title": "3  Ten additional geoms for ggplot2",
    "section": "3.9 08 Treemaps",
    "text": "3.9 08 Treemaps\nYou can visualize hierarchical data with a treemap, because the area of the rectangle is chosen proportionally to the size of each cluster. Before he was banned, Donald Trump was a huge fan of Twitter and Axios collected and categorized his tweets. Some tweets were about the media, democrats, and the grand old party (GOP), with further subgroups within each category. I used this data and the treemapify package to make a treemap (Wilkins 2021). Mr. Trump tweeted a lot about “the media” and the “Democrats” in 2019.\n\n\n\n\n\nThe data of the last plot is not available, but you can use the gapminder data to explore how treemapify works.\n\n#Minimal code example #####\nlibrary(treemapify)\nlibrary(gapminder)\n\ndata &lt;- gapminder::gapminder |&gt; \n  dplyr::filter(year == 2007 & continent == \"Europe\")\n\nggplot(data, aes(area = gdpPercap, \n                 fill = lifeExp, \n                 label = country)) +\n  geom_treemap() +\n  geom_treemap_text(color = \"white\", \n                    grow = TRUE)"
  },
  {
    "objectID": "03_ggplot2_ext.html#waffle-charts",
    "href": "03_ggplot2_ext.html#waffle-charts",
    "title": "3  Ten additional geoms for ggplot2",
    "section": "3.10 09 Waffle charts",
    "text": "3.10 09 Waffle charts\nDo not make a pie, make a waffle. Waffle charts depict a whole (or part of the whole), and it gives the audience visual clues to assess the size of each group, especially if each square represents exactly one percentage point. The example plot illustrates the “leaky pipeline” in academic careers. Did you know that after each transition step in higher education (e.g., graduation, Ph.D.), more men than women remain in the system? The sex ratios become more and more skewed till the end of the academic pathway. I used a waffle chart to illustrate the leaky pipeline for Germany in 2020.\n\n\n\n\n\nThe waffle package makes it easy to create waffle charts (Rudis and Gandy 2017). It only needs a numerical input to create the chart and the function returns a ggplot2 object.\n\n#Minimal code example #####\nlibrary(waffle)\nparts &lt;- c(66, 22, 12)\n\nwaffle(parts, rows = 10)"
  },
  {
    "objectID": "03_ggplot2_ext.html#word-clouds",
    "href": "03_ggplot2_ext.html#word-clouds",
    "title": "3  Ten additional geoms for ggplot2",
    "section": "3.11 10 Word clouds",
    "text": "3.11 10 Word clouds\nUse a word cloud to depict the result of a text analysis. A word cloud displays, for example, the frequency of words by its font size. The plot shows the word cloud of a children’s book that I made with the ggwordcloud package (Le Pennec and Slowikowski 2022). Do you know which one? Witches and wizards play a big role in this book.\n\n\n\n\n\nCreating a word cloud is not rocket since, but working with text is a complicated topic in the beginning. Fortunately, there is no need to learn text mining first, the ggwordcloud package includes data to make word clouds. Consider reading Text Mining with R by Silge and Robinson (2017) to learn more about text mining.\n\n#Minimal code example by Erwan Le Pennec \nlibrary(ggwordcloud)\n#set a seed (starting point)\nset.seed(123)\n\nggplot(love_words_small, aes(label = word, \n                             size = speakers)) +\n  geom_text_wordcloud() +\n  scale_size_area(max_size = 30)"
  },
  {
    "objectID": "03_ggplot2_ext.html#summary",
    "href": "03_ggplot2_ext.html#summary",
    "title": "3  Ten additional geoms for ggplot2",
    "section": "3.12 Summary",
    "text": "3.12 Summary\nThis blog highlighted packages to extend the possibilities of ggplot2, but there are too many to discuss them all. For example, ggtext helps to handle text (Wilke 2020); you can visualize the results of a survival analysis with survminer (Kassambara, Kosinski, and Biecek 2021); or create cool animations with gganimate (Pedersen and Robinson 2022).\nFinally, go and visit the ggplot2 website to explore more extensions.\n\n\n\n\nBrunson, Jason Cory, and Quentin D. Read. 2020. Ggalluvial: Alluvial Plots in Ggplot2. https://CRAN.R-project.org/package=ggalluvial.\n\n\nClarke, Erik, and Scott Sherrill-Mix. 2017. Ggbeeswarm: Categorical Scatter (Violin Point) Plots. https://CRAN.R-project.org/package=ggbeeswarm.\n\n\nHorst, Allison Marie, Alison Presmanes Hill, and Kristen B Gorman. 2020. “Palmerpenguins: Palmer Archipelago (Antarctica) Penguin Data.” https://doi.org/10.5281/zenodo.3960218.\n\n\nJeppson, Haley, Heike Hofmann, and Di Cook. 2021. Ggmosaic: Mosaic Plots in the Ggplot2 Framework. https://CRAN.R-project.org/package=ggmosaic.\n\n\nKahle, David, and Hadley Wickham. 2013. “Ggmap: Spatial Visualization with Ggplot2.” The R Journal 5 (1): 144–61. https://journal.r-project.org/archive/2013-1/kahle-wickham.pdf.\n\n\nKahle, David, Hadley Wickham, and Scott Jackson. 2019. Ggmap: Spatial Visualization with Ggplot2. https://CRAN.R-project.org/package=ggmap.\n\n\nKassambara, Alboukadel, Marcin Kosinski, and Przemyslaw Biecek. 2021. Survminer: Drawing Survival Curves Using Ggplot2. https://CRAN.R-project.org/package=survminer.\n\n\nLe Pennec, Erwan, and Kamil Slowikowski. 2022. Ggwordcloud: A Word Cloud Geom for Ggplot2.\n\n\nNeitmann, Thomas. 2020. Ggcharts: Shorten the Distance from Data Visualization Idea to Actual Plot. https://CRAN.R-project.org/package=ggcharts.\n\n\nPedersen, Thomas Lin, and David Robinson. 2022. Gganimate: A Grammar of Animated Graphics. https://CRAN.R-project.org/package=gganimate.\n\n\nRudis, Bob, and Dave Gandy. 2017. Waffle: Create Waffle Chart Visualizations in r. https://CRAN.R-project.org/package=waffle.\n\n\nSilge, Julia, and David Robinson. 2017. Text Mining with R: A Tidy Approach. Beijing; Boston: O’Reilly.\n\n\nWilke, Claus O. 2020. Ggtext: Improved Text Rendering Support for ’Ggplot2’. https://CRAN.R-project.org/package=ggtext.\n\n\n———. 2021. Ggridges: Ridgeline Plots in ’Ggplot2’. https://CRAN.R-project.org/package=ggridges.\n\n\nWilkins, David. 2021. Treemapify: Draw Treemaps in ’Ggplot2’. https://CRAN.R-project.org/package=treemapify."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Allaire, JJ, Yihui Xie, Jonathan McPherson, Javier Luraschi, Kevin\nUshey, Aron Atkins, Hadley Wickham, Joe Cheng, Winston Chang, and\nRichard Iannone. 2022. Rmarkdown: Dynamic Documents for r. https://CRAN.R-project.org/package=rmarkdown.\n\n\nBrunson, Jason Cory, and Quentin D. Read. 2020. Ggalluvial: Alluvial\nPlots in Ggplot2. https://CRAN.R-project.org/package=ggalluvial.\n\n\nClarke, Erik, and Scott Sherrill-Mix. 2017. Ggbeeswarm: Categorical\nScatter (Violin Point) Plots. https://CRAN.R-project.org/package=ggbeeswarm.\n\n\nCsárdi, Gábor. 2022. “Keyring: Access the System Credential Store\nfrom r.” https://CRAN.R-project.org/package=keyring.\n\n\nGrothendieck, G. 2017. “Sqldf: Manipulate r Data Frames Using\nSQL.” https://CRAN.R-project.org/package=sqldf.\n\n\nGrün, Bettina, and Achim Zeileis. 2009. “Automatic Generation of\nExams in r” 29. https://doi.org/10.18637/jss.v029.i10.\n\n\nHorst, Allison Marie, Alison Presmanes Hill, and Kristen B Gorman. 2020.\n“Palmerpenguins: Palmer Archipelago (Antarctica) Penguin\nData.” https://doi.org/10.5281/zenodo.3960218.\n\n\nJeppson, Haley, Heike Hofmann, and Di Cook. 2021. Ggmosaic: Mosaic\nPlots in the Ggplot2 Framework. https://CRAN.R-project.org/package=ggmosaic.\n\n\nKahle, David, and Hadley Wickham. 2013. “Ggmap: Spatial\nVisualization with Ggplot2.” The R Journal 5 (1):\n144–61. https://journal.r-project.org/archive/2013-1/kahle-wickham.pdf.\n\n\nKahle, David, Hadley Wickham, and Scott Jackson. 2019. Ggmap:\nSpatial Visualization with Ggplot2. https://CRAN.R-project.org/package=ggmap.\n\n\nKassambara, Alboukadel, Marcin Kosinski, and Przemyslaw Biecek. 2021.\nSurvminer: Drawing Survival Curves Using Ggplot2. https://CRAN.R-project.org/package=survminer.\n\n\nLe Pennec, Erwan, and Kamil Slowikowski. 2022. Ggwordcloud: A Word\nCloud Geom for Ggplot2.\n\n\nMüller, Kirill, Hadley Wickham, David A. James, and Seth Falcon. 2022.\nRSQLite: SQLite Interface for r. https://CRAN.R-project.org/package=RSQLite.\n\n\nNeitmann, Thomas. 2020. Ggcharts: Shorten the Distance from Data\nVisualization Idea to Actual Plot. https://CRAN.R-project.org/package=ggcharts.\n\n\nPedersen, Thomas Lin, and David Robinson. 2022. Gganimate: A Grammar\nof Animated Graphics. https://CRAN.R-project.org/package=gganimate.\n\n\nR Special Interest Group on Databases (R-SIG-DB), Hadley Wickham, and\nKirill Müller. 2022. DBI: R Database Interface. https://CRAN.R-project.org/package=DBI.\n\n\nRudis, Bob, and Dave Gandy. 2017. Waffle: Create Waffle Chart\nVisualizations in r. https://CRAN.R-project.org/package=waffle.\n\n\nSilge, Julia, and David Robinson. 2017. Text Mining\nwith R: A Tidy\nApproach. Beijing; Boston: O’Reilly.\n\n\nUshey, Kevin, JJ Allaire, Hadley Wickham, and Gary Ritchie. 2023.\n“Rstudioapi: Safely Access the RStudio API.” https://CRAN.R-project.org/package=rstudioapi.\n\n\nWickham, Hadley. 2022. Tidyverse: Easily Install and Load the\nTidyverse. https://CRAN.R-project.org/package=tidyverse.\n\n\nWickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen,\nKohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, and Dewey\nDunnington. 2022. Ggplot2: Create Elegant Data Visualisations Using\nthe Grammar of Graphics. https://CRAN.R-project.org/package=ggplot2.\n\n\nWickham, Hadley, Romain François, Lionel Henry, Kirill Müller, and Davis\nVaughan. 2023. “Dplyr: A Grammar of Data Manipulation.” https://CRAN.R-project.org/package=dplyr.\n\n\nWickham, Hadley, Maximilian Girlich, and Edgar Ruiz. 2022. Dbplyr: A\nDplyr Back End for Databases. https://CRAN.R-project.org/package=dbplyr.\n\n\nWilke, Claus O. 2020. Ggtext: Improved Text Rendering Support for\n’Ggplot2’. https://CRAN.R-project.org/package=ggtext.\n\n\n———. 2021. Ggridges: Ridgeline Plots in ’Ggplot2’. https://CRAN.R-project.org/package=ggridges.\n\n\nWilkins, David. 2021. Treemapify: Draw Treemaps in ’Ggplot2’.\nhttps://CRAN.R-project.org/package=treemapify."
  }
]